\documentclass[10pt,a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\usepackage{thmbox}
\usepackage{enumerate}
\usepackage{subcaption}

\geometry{
a4paper,
body={150mm,260mm},
left=30mm,top=15mm,
headheight=7mm,headsep=4mm,
marginparsep=4mm,
marginparwidth=27mm}


\pagestyle{empty}

\providecommand{\abs}[1]{\left|#1\right|}
\providecommand{\C}{\mathbb{C}}
\providecommand{\R}{\mathbb{R}}
\providecommand{\E}{\mathbb{E}}
\providecommand{\Prob}{\mathbb{P}}
\providecommand{\ii}{\mathrm{i}}
\providecommand{\w}{\omega}
\providecommand{\one}{\textbf{1}}

\renewcommand{\S}{\textbf{S}^n}

\newcommand{\norm}[1]{\Arrowvert#1\Arrowvert_2}

\newcount\colveccount

\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{pmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{pmatrix}
        \fi
}
 
\author{Judith Abecassis \& Timoth√©e Lacroix}

\title{Idea for loss estimate}

\begin{document}
We have
$$\E[O_{t,i} | \mathcal{F}_{t-1}] = p_{t,i} + (1-p_{t,i})\Prob(\exists j \in \mathcal{N}_i~s.t.~I_t=j | \mathcal{F}_{t-1}, I_t\neq i) = p_{t,i} + (1-p_{t,i})r_{BA} $$
With $\mathcal{N}_i$ the neighborhood of node $i$, and $\Prob(k)$ the probability in the Barabasi-Albert model that a node has a degree of $k$.

\begin{align*}
  r_{BA} &= \sum_{k=1}^{N-1} \Prob(k)\Prob(\exists j \in \mathcal{N}_i~s.t.~I_{t}=j | \mathcal{F}_{t-1}, \card(\mathcal{N}_i=k|), I_{t}\neq i)\\
    &= \sum_{k=1}^{N-1} \Prob(k) \binom{N-1}{k}^{-1} \sum_{\mathcal{K} = \mathcal{N}^k_i}\sum_{j \in \mathcal{K}} \Prob(I_t=j|I_t\neq i) \quad \text{(each $\Prob(I_t=j|I_t\neq i)$ appears exactly $\binom{N-2}{k-1}$ times)} \\
    &= \sum_{k=1}^{N-1} \Prob(k) \binom{N-1}{k}^{-1} \binom{N-2}{k-1} \quad \text{(since $\sum_{i \neq j}\Prob(I_t=j|I_t\neq i)=1$)} \\
    &= \sum_{k=1}^{N-1}\Prob(k)\frac{k(N-1-k)}{N-1}
\end{align*}

These loss estimates should then be unbiased : 
$$\hat{l}_{t,i} = \frac{O_{t,i}l_{t,i}}{p_{t,i}+(1-p_{t,i})r_{BA}}$$ \\

For $r_{BA}$, we can either use : 
$$ \Prob(k) = \frac{2m^2t}{m_0+t}k^{-3} $$
Or, if we suppose the graph is in his asymptotic regime : 
$$ \Prob(k) = \frac{k^{-3}}{\sum_{i=1}^{N-1}i^{-3}} $$

\end{document}